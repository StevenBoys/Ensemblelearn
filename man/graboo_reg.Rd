% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient_boosting.R
\name{graboo_reg}
\alias{graboo_reg}
\title{Function that builds weak model on Gradient Boosting for regression task}
\usage{
graboo_reg(x, y, last_est, loss = mse, eta = 0.1)
}
\arguments{
\item{x}{- input independent variables x for the training}

\item{y}{- input dependent variable y for the traisning}

\item{last_est}{- the output estimate from the last step}

\item{loss}{- the loss function used, its default value is the mean of the square error}

\item{eta}{- the step size we use to update the total estimate each time, its default value is 0.1}
}
\value{
The trained results of weak model on Gradient Boosting.
}
\description{
Function that builds weak model on Gradient Boosting for regression task
}
\examples{
x <- matrix(rnorm(4000), 200, 20)
beta <- rnorm(5)
y <- x[, 1:length(beta)] \%*\% beta + rnorm(200)
last_est <- rep(0, ncol(x))
graboo_reg(x, y, last_est)
}
